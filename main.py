import streamlit as st
import json
import base64
import re
import os
from prompt_engine import generate_experiment_plan


def sanitize_text(text):
    if not text or not isinstance(text, str):
        return ""
    text = text.replace("\n", " ").replace("\r", " ").replace("\t", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def safe_display(text, method=st.info):
    clean_text = sanitize_text(text)
    method(clean_text)


def extract_json(text):
    try:
        match = re.search(r"\{[\s\S]+\}", text)
        return match.group(0) if match else text
    except:
        return text


def remove_units_from_text(text, unit):
    if not text or not unit.strip():
        return text
    escaped_unit = re.escape(unit.strip())
    return re.sub(rf"(\d+\.?\d*)\s*{escaped_unit}", r"\1", text)


def insert_units_in_goal(text, unit):
    if not text or not unit.strip():
        return text
    return re.sub(r"(\d+\.?\d*)", r"\1" + unit, text)


st.set_page_config(page_title="A/B Test Architect", layout="wide")
st.title("üß™ AI-Powered A/B Test Architect")
st.markdown("Use Groq + LLMs to design smarter experiments from fuzzy product goals.")

# --- Product Context ---
st.header("üß† Product Context")
product_type = st.radio("Product Type *", ["SaaS", "Consumer App", "E-commerce", "Marketplace", "Gaming", "Other"], horizontal=True)
user_base = st.radio("User Base Size (DAU) *", ["< 10K", "10K‚Äì100K", "100K‚Äì1M", "> 1M"], horizontal=True)
metric_focus = st.radio("Primary Metric Focus *", ["Activation", "Retention", "Monetization", "Engagement", "Virality"], horizontal=True)
product_notes = st.text_area("Anything unique about your product or users?", placeholder="e.g. drop-off at pricing, seasonality, power users...")

# --- Goal Inputs ---
st.markdown("## üéØ Metric Improvement Objective")
exact_metric = st.text_input("üéØ Metric to Improve * (e.g. Activation Rate, ARPU, DAU/MAU)")
metric_unit = st.text_input("üìê Metric Unit (e.g. %, $, secs, count)", value="%")
current_value_raw = st.text_input("üìâ Current Metric Value * (numerical only)")
target_value_raw = st.text_input("üöÄ Target Metric Value * (numerical only)")

# --- Generate Plan ---
if st.button("Generate Plan"):
    missing = []
    if not product_type: missing.append("Product Type")
    if not user_base: missing.append("User Base Size")
    if not metric_focus: missing.append("Primary Metric Focus")
    if not exact_metric.strip(): missing.append("Metric to Improve")
    if not current_value_raw.strip(): missing.append("Current Value")
    if not target_value_raw.strip(): missing.append("Target Value")
    if not metric_unit.strip(): missing.append("Metric Unit")

    if missing:
        st.warning("Please fill all required fields: " + ", ".join(missing))
        st.stop()

    try:
        current = float(current_value_raw)
        target = float(target_value_raw)
        expected_lift = round(target - current, 4)
        mde = round(abs((target - current) / current), 4) if current != 0 else 0
    except ValueError:
        st.error("Metric values must be numeric.")
        st.stop()

    auto_goal = f"I want to improve {exact_metric} from {current} to {target}."
    st.session_state.auto_goal = auto_goal

    context = {
        "type": product_type,
        "users": user_base,
        "metric": metric_focus,
        "notes": product_notes,
        "exact_metric": exact_metric,
        "current_value": current,
        "target_value": target,
        "expected_lift": expected_lift,
        "minimum_detectable_effect": mde,
        "metric_unit": metric_unit.strip()
    }
    st.session_state.context = context

    output = generate_experiment_plan(auto_goal, context)
    st.session_state.output = output
    st.session_state.hypothesis_confirmed = False
    st.session_state.selected_index = None

# --- Output UI ---
if "output" in st.session_state:
    raw_output = extract_json(st.session_state.output)

    try:
        plan = json.loads(raw_output)
        print("‚úÖ Parsed JSON:", json.dumps(plan, indent=2))
    except Exception as e:
        st.error("‚ö†Ô∏è The plan couldn't be parsed. This might be due to malformed LLM output.")
        st.code(raw_output)
        st.stop()

    unit_raw = st.session_state.context.get("metric_unit", "")
    unit = f" {unit_raw.strip()}" if unit_raw.strip() else ""

    # Inferred Product Goal
    st.markdown("## ‚úçÔ∏è Inferred Product Goal")
    safe_display(st.session_state.auto_goal, method=st.info)

    # Problem Statement
    st.subheader("üß© Problem Statement")
    raw_problem_statement = plan.get("problem_statement", "")
    problem_statement = remove_units_from_text(raw_problem_statement, unit)
    if not problem_statement or len(problem_statement.strip()) < 10:
        problem_statement = "‚ö†Ô∏è Problem statement not generated by the model."
    safe_display(problem_statement, method=st.info)

    # Hypotheses
    st.subheader("üß™ Choose a Hypothesis")
    hypotheses = plan.get("hypotheses", [])
    if not hypotheses:
        st.warning("No hypotheses found in the generated plan.")
    else:
        for i, h in enumerate(hypotheses):
            hypo = h.get("hypothesis") if isinstance(h, dict) else str(h)
            with st.expander(f"H{i+1}: {hypo}", expanded=(st.session_state.selected_index == i)):
                if st.button(f"‚úÖ Select H{i+1}", key=f"select_{i}"):
                    st.session_state.selected_index = i
                    st.session_state.hypothesis_confirmed = True

    # Selected Hypothesis Details
    if st.session_state.get("hypothesis_confirmed") and st.session_state.selected_index is not None:
        i = st.session_state.selected_index
        selected_hypo_obj = hypotheses[i] if i < len(hypotheses) else {}
        selected_hypo = selected_hypo_obj.get("hypothesis", "N/A")

        effort_list = plan.get("effort", [])
        effort = effort_list[i].get("effort", "N/A") if i < len(effort_list) else "N/A"

        variant_list = plan.get("variants", [])
        variant = variant_list[i] if i < len(variant_list) else {}
        control = variant.get("control", "Not specified")
        variation = variant.get("variation", "Not specified")

        rationale_list = plan.get("hypothesis_rationale", [])
        rationale = "Not available"
        if i < len(rationale_list):
            item = rationale_list[i]
            if isinstance(item, dict):
                rationale = item.get("rationale", "Not available")
            elif isinstance(item, str) and len(item.strip()) > 10:
                rationale = item.strip()
        rationale = sanitize_text(rationale)

        st.subheader("üìâ Selected Hypothesis")
        st.success(selected_hypo)
        st.markdown(f"**Effort**: {effort}")
        st.markdown(f"**Why this Hypothesis?**\n\n{rationale}")
        st.markdown(f"**Control Variant:**\n```text\n{control}\n```")
        st.markdown(f"**Test Variant:**\n```text\n{variation}\n```")

        teams = plan.get("team_involved", [])
        if teams:
            st.markdown(f"**Teams Involved:** {', '.join(teams)}")

        criteria = plan.get("success_criteria", {})
        st.markdown("### üéØ Success Criteria")

        try:
            conf_level = float(criteria.get("confidence_level", 0))
            if conf_level <= 1:  # e.g., 0.95
                conf_display = f"{round(conf_level * 100)}%"
            else:  # e.g., 95
                conf_display = f"{round(conf_level)}%"
        except:
            conf_display = "N/A"

        expected_lift = criteria.get("expected_lift", "N/A")
        try:
            expected_lift_val = float(expected_lift)
            expected_lift_str = f"{expected_lift_val}{unit}"
        except:
            expected_lift_str = expected_lift

        try:
            mde = float(criteria.get("MDE", 0))
            mde_display = f"{round(mde * 100)}%"
        except:
            mde_display = "N/A"

        test_duration = criteria.get("estimated_test_duration", "N/A")

        st.markdown(f"- **Confidence Level**: {conf_display}")
        st.markdown(f"- **Expected Lift**: {expected_lift_str}")
        st.markdown(f"- **Minimum Detectable Effect**: {mde_display}")
        st.markdown(f"- **Test Duration**: {test_duration} days")

        risks = plan.get("risks_and_assumptions", [])
        risks = [sanitize_text(r) for r in risks if isinstance(r, str) and r.strip()]
        if not risks:
            risks = ["No risks or assumptions were provided."]
        st.markdown("### ‚ö†Ô∏è Risks and Assumptions")
        st.code("\n- " + "\n- ".join(risks))

        steps = plan.get("next_steps") or ["Not specified"]
        steps = [sanitize_text(s) for s in steps]
        st.markdown("### ‚úÖ Next Steps")
        st.code("\n- " + "\n- ".join(steps))

        # --- Generate Polished PRD ---
        export = f"""# üìÑ Experiment PRD: {selected_hypo[:60]}

## üß© Problem Statement
{problem_statement}

## üéØ Objective
Increase {exact_metric} from {current} to {target} by launching a targeted experiment.

## üß™ Hypothesis
{selected_hypo}

## üîÅ Test Variants
- **Control**: {control}
- **Variation**: {variation}

## üí° Rationale
{rationale}

## üìä Success Criteria
| Metric                     | Value                |
|---------------------------|----------------------|
| Confidence Level          | {conf_display}       |
| Expected Lift             | {expected_lift_str}  |
| Minimum Detectable Effect | {mde_display}        |
| Test Duration             | {test_duration} days |

## üìà Metrics to Track
"""
        for metric in plan.get("metrics", []):
            name = metric.get("name", "Unnamed Metric")
            formula = metric.get("formula", "N/A")
            export += f"- **{name}**: {formula}\n"

        export += "\n## üë• Segments for Breakdown\n"
        segments = plan.get("segments", [])
        for seg in segments:
            export += f"- {seg}\n"

        export += f"\n## ‚öôÔ∏è Implementation Effort\n- **Effort**: {effort}\n- **Teams Involved**: {', '.join(teams)}\n"

        export += "\n## ‚ö†Ô∏è Risks and Assumptions\n"
        for r in risks:
            export += f"- {r}\n"

        export += "\n## ‚úÖ Next Steps\n"
        for step in steps:
            export += f"- {step}\n"
        b64 = base64.b64encode(export.encode()).decode()
        href = f'<a href="data:file/txt;base64,{b64}" download="experiment_prd.txt">üì• Download PRD</a>'
        st.markdown(href, unsafe_allow_html=True)

if __name__ == "__main__":
    print("‚úÖ Streamlit app loaded successfully.")
